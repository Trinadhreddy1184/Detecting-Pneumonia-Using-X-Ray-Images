{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzOLYA4R-KkR"
   },
   "source": [
    "# Background Info\n",
    "\n",
    "The following notebook contains the source code for all of the code used in our project, formatted in the order to match the report and slides order. Our actual code was run in several different notebooks across group members, which is why you will not see outputs from previously loaded runtimes in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jHKK4JYQ98LZ"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "from tensorflow.keras.applications import MobileNetV2,ResNet50\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7hfFk8TDx7C"
   },
   "source": [
    "# 1 - Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXnbrQa7Dw9D"
   },
   "outputs": [],
   "source": [
    "# Download dataset using kagglehub\n",
    "import kagglehub\n",
    "dataset_path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "\n",
    "print(f\"Dataset downloaded to: {dataset_path}\")\n",
    "\n",
    "# Print directory structure\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    print(f\"Directory: {root}\")\n",
    "    print(f\"Subdirectories: {dirs}\")\n",
    "    print(f\"Files: {files}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYjOjBquEIMc"
   },
   "source": [
    "# 2 - Partition Images of Training and Test Data to Seperate Pandas Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wh7U2hdpDskV"
   },
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "def prepare_dataset(data_dir):\n",
    "    filepaths, labels = [], []\n",
    "    for category in os.listdir(data_dir):\n",
    "        category_path = os.path.join(data_dir, category)\n",
    "        for img_file in os.listdir(category_path):\n",
    "            filepaths.append(os.path.join(category_path, img_file))\n",
    "            labels.append(category)\n",
    "    return pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
    "\n",
    "train_dir = os.path.join(dataset_path, \"chest_xray/train\")\n",
    "test_dir = os.path.join(dataset_path, \"chest_xray/test\")\n",
    "\n",
    "df_train = prepare_dataset(train_dir)\n",
    "df_test = prepare_dataset(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ToFVosGYhoB8"
   },
   "outputs": [],
   "source": [
    "# Visualize label distribution\n",
    "def plot_label_distribution(df, title):\n",
    "    label_counts = df['label'].value_counts()\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 4), facecolor='white')\n",
    "    palette = sns.color_palette(\"coolwarm\")\n",
    "\n",
    "    # Pie chart\n",
    "    axs[0].pie(label_counts, labels=label_counts.index, autopct='%1.1f%%', startangle=140, colors=palette)\n",
    "    axs[0].set_title(f'{title} - Pie Chart')\n",
    "\n",
    "    # Bar chart\n",
    "    sns.barplot(x=label_counts.index, y=label_counts.values, ax=axs[1], palette=palette)\n",
    "    axs[1].set_title(f'{title} - Bar Chart')\n",
    "    axs[1].set_xlabel('Categories')\n",
    "    axs[1].set_ylabel('Counts')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_label_distribution(df_train, \"Training Data\")\n",
    "plot_label_distribution(df_test, \"Testing Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uL1-eJLChwJr"
   },
   "source": [
    "# 3 - Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeRo-K0vmAy7"
   },
   "source": [
    "The following commented out code is our old preprocessing code before we added data augmentation. This was our code by Phase 1 PPU.\n",
    "\n",
    "The code after this cell is the finalized preprocessing code, with data augmentation applied-- which improved model accuracy in training and testing across all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "x2DWdvoYup5v",
    "outputId": "2b9cce8f-629f-44c6-c9e6-45cb9c221c83"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n# Image dimensions and batch size\\nIMAGE_SIZE = (256, 256)\\nBATCH_SIZE = 32\\n\\n# Create datasets\\ntrain_dataset = image_dataset_from_directory(\\n    train_dir, validation_split=0.1, subset=\"training\", seed=123,\\n    image_size=IMAGE_SIZE, batch_size=BATCH_SIZE\\n)\\nval_dataset = image_dataset_from_directory(\\n    train_dir, validation_split=0.1, subset=\"validation\", seed=123,\\n    image_size=IMAGE_SIZE, batch_size=BATCH_SIZE\\n)\\ntest_dataset = image_dataset_from_directory(\\n    test_dir, seed=123, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE\\n)\\n\\n# Normalize pixel values\\ndef normalize_dataset(ds):\\n    return ds.map(lambda x, y: (x / 255.0, y))\\n\\ntrain_dataset = normalize_dataset(train_dataset)\\nval_dataset = normalize_dataset(val_dataset)\\ntest_dataset = normalize_dataset(test_dataset)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Image dimensions and batch size\n",
    "IMAGE_SIZE = (256, 256)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir, validation_split=0.1, subset=\"training\", seed=123,\n",
    "    image_size=IMAGE_SIZE, batch_size=BATCH_SIZE\n",
    ")\n",
    "val_dataset = image_dataset_from_directory(\n",
    "    train_dir, validation_split=0.1, subset=\"validation\", seed=123,\n",
    "    image_size=IMAGE_SIZE, batch_size=BATCH_SIZE\n",
    ")\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir, seed=123, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Normalize pixel values\n",
    "def normalize_dataset(ds):\n",
    "    return ds.map(lambda x, y: (x / 255.0, y))\n",
    "\n",
    "train_dataset = normalize_dataset(train_dataset)\n",
    "val_dataset = normalize_dataset(val_dataset)\n",
    "test_dataset = normalize_dataset(test_dataset)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y1ItY5WPhpIy"
   },
   "outputs": [],
   "source": [
    "#Preprocessing V2 - With Data augmentation techniques\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Image dimensions and batch size\n",
    "IMAGE_SIZE = (256, 256)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create data augmentation object\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,  # Normalize pixel values\n",
    "    rotation_range=20,    # Rotate images randomly within 20 degrees\n",
    "    width_shift_range=0.1,  # Shift horizontally by 10%\n",
    "    height_shift_range=0.1,  # Shift vertically by 10%\n",
    "    shear_range=0.1,       # Apply shearing\n",
    "    zoom_range=0.2,        # Random zoom\n",
    "    horizontal_flip=True,  # Flip horizontally\n",
    "    validation_split=0.1   # Reserve 10% of training data for validation\n",
    ")\n",
    "\n",
    "# Load augmented training data\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',  # Use binary mode for binary classification\n",
    "    subset='training',    # Training subset\n",
    "    seed=123              # Ensure reproducibility\n",
    ")\n",
    "\n",
    "# Load validation data (no augmentation, just rescaling)\n",
    "val_datagen = ImageDataGenerator(rescale=1.0 / 255.0, validation_split=0.1)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Test dataset (no augmentation, just rescaling)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False  # Do not shuffle for consistent evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGfizjpOjY2Z"
   },
   "source": [
    "# 4. Vizualization of Examples from Training Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhgWktrmjYaa"
   },
   "outputs": [],
   "source": [
    "# Visualize images from a given directory\n",
    "def visualize_sample_images(data_dir, title, num_images=5):\n",
    "    image_paths = os.listdir(data_dir)[:num_images]\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3), facecolor='white')\n",
    "    for i, img_file in enumerate(image_paths):\n",
    "        img = plt.imread(os.path.join(data_dir, img_file))\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(img_file[:10])  # Show partial filename\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_sample_images(os.path.join(train_dir, \"NORMAL\"), \"Sample Normal Images (from dir, not augmented training data)\")\n",
    "visualize_sample_images(os.path.join(train_dir, \"PNEUMONIA\"), \"Sample Pneumonia Images (from dir, not augmented training data)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMuzDSQcjgBn"
   },
   "outputs": [],
   "source": [
    "# Plot training accuracy and loss\n",
    "def plot_training_history(history):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6), facecolor='white')\n",
    "\n",
    "    # Accuracy plot\n",
    "    axs[0].plot(history.history['accuracy'], label='Train Accuracy', color='blue')\n",
    "    axs[0].plot(history.history['val_accuracy'], label='Validation Accuracy', color='orange')\n",
    "    axs[0].set_title('Accuracy over Epochs')\n",
    "    axs[0].set_xlabel('Epochs')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Loss plot\n",
    "    axs[1].plot(history.history['loss'], label='Train Loss', color='blue')\n",
    "    axs[1].plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "    axs[1].set_title('Loss over Epochs')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krxR3mC9kEJ1"
   },
   "source": [
    "# ResNet50 Model(s)\n",
    "\n",
    "Below is the function we will use later for fine-tuning. But before that, we will utilize transfer learning, by adding a few trainable layers to the end of the ResNet50 model, and the layers in the ResNet model will be FROZEN and pretrained with \"ImageNet\" weights. Using model.summary(), we also display the underlying architecture of ResNet50, to give us an idea of which layers to unfreeze/freeze.\n",
    "\n",
    "ImageNet is a super large dataset that ResNet50 is trained on, making the model by default trained for feature extraction. The added layers will take the extracted feature information, and tie it towards our dataset to to make a calculated prediction. This is the basic idea of transfer learning to our understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKdi5RTJkPcp"
   },
   "outputs": [],
   "source": [
    "# Unfreeze the last few layers of ResNet50\n",
    "def fine_tune_resnet50_model(model, num_layers_to_unfreeze):\n",
    "    base_model = model.layers[0]  # Extract the pre-trained ResNet50 base model\n",
    "    for layer in base_model.layers[-num_layers_to_unfreeze:]:\n",
    "        layer.trainable = True  # Unfreeze these layers\n",
    "\n",
    "    # Compile the model again with a lower learning rate\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),  # Fine-tuning requires a smaller learning rate\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "base_model = ResNet50(input_shape=(*IMAGE_SIZE, 3), include_top=False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KdqztzckSHn"
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    base_model = ResNet50(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n",
    "\n",
    "    base_model.trainable = False  # Unfreeze the base model (deeper layers to adapt these specific features to the pneumonia dataset)\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model((*IMAGE_SIZE, 3))\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_generator, validation_data=val_generator, epochs=10, callbacks=[early_stopping]\n",
    ")\n",
    "model.summary()\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tO2Ers2sl3h4"
   },
   "source": [
    "Transfer Learning Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TfZyr5uJkXSd"
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7sqeMNCljEb"
   },
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "794RvWMWljZZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int).flatten()  # Convert probabilities to binary classes\n",
    "y_true = test_generator.classes  # True labels from the generator\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes, labels=[0, 1])\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_generator.class_indices.keys())\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J19--m21lw9-"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Finetuned model\n",
    "\n",
    "model = fine_tune_resnet50_model(model, num_layers_to_unfreeze=10)\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_generator, validation_data=val_generator, epochs=10, callbacks=[early_stopping]\n",
    ")\n",
    "model.summary()\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_0o3Ewum1zj"
   },
   "source": [
    "Finetuned model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XAUOAyoFly4z"
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhFGcTBksO4D"
   },
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aALBtWfjsSUW"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int).flatten()  # Convert probabilities to binary classes\n",
    "y_true = test_generator.classes  # True labels from the generator\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes, labels=[0, 1])\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_generator.class_indices.keys())\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwBKAeUltTfq"
   },
   "source": [
    "# Custom CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5WxQvCltT2n"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "def build_custom_cnn(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Block 1\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))  # Extract features with 32 filters\n",
    "    model.add(BatchNormalization())  # Normalize activations for faster convergence\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  # Downsample spatial dimensions\n",
    "    model.add(Dropout(0.25))  # Mitigate overfitting\n",
    "\n",
    "    # Block 2\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))  # Extract deeper features with 64 filters\n",
    "    model.add(BatchNormalization())  # Normalize activations for stability\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  # Reduce spatial dimensions\n",
    "    model.add(Dropout(0.25))  # Prevent overfitting\n",
    "\n",
    "    # Block 3\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))  # Extract higher-level features with 128 filters\n",
    "    model.add(BatchNormalization())  # Normalize activations\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))  # Further reduce spatial dimensions\n",
    "    model.add(Dropout(0.25))  # Mitigate overfitting\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    model.add(Flatten())  # Flatten feature maps for dense layers\n",
    "    model.add(Dense(128, activation='relu'))  # Dense layer with ReLU activation\n",
    "    model.add(Dropout(0.5))  # Reduce overfitting\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Activation function for binary classification\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer='adam',  # Adaptive learning rate optimization\n",
    "        loss='binary_crossentropy',  # Loss for binary classification\n",
    "        metrics=['accuracy']  # Track accuracy during training\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3xRSF7Hul_d"
   },
   "outputs": [],
   "source": [
    "# Define the input shape (e.g., (256, 256, 3) for RGB images of size 256x256)\n",
    "input_shape = (*IMAGE_SIZE, 3)\n",
    "\n",
    "# Build the model\n",
    "custom_cnn_model = build_custom_cnn(input_shape)\n",
    "\n",
    "# Train the model\n",
    "history = custom_cnn_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGZXIO-otss1"
   },
   "outputs": [],
   "source": [
    "# Plot training accuracy and loss\n",
    "def plot_training_history(history):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6), facecolor='white')\n",
    "\n",
    "    # Accuracy plot\n",
    "    axs[0].plot(history.history['accuracy'], label='Train Accuracy', color='blue')\n",
    "    axs[0].plot(history.history['val_accuracy'], label='Validation Accuracy', color='orange')\n",
    "    axs[0].set_title('Accuracy over Epochs')\n",
    "    axs[0].set_xlabel('Epochs')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Loss plot\n",
    "    axs[1].plot(history.history['loss'], label='Train Loss', color='blue')\n",
    "    axs[1].plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "    axs[1].set_title('Loss over Epochs')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jlBQqIWGts_N"
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = custom_cnn_model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Adn1mDRtUPi"
   },
   "source": [
    "# MobileNetV2 Model (transfer learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-R5_x47tUqM"
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "def build_model(input_shape):\n",
    "    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n",
    "    base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model((*IMAGE_SIZE, 3))\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_dataset, validation_data=val_dataset, epochs=15, callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fc0iBTDRtl1k"
   },
   "outputs": [],
   "source": [
    "# Plot training accuracy and loss\n",
    "def plot_training_history(history):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6), facecolor='white')\n",
    "\n",
    "    # Accuracy plot\n",
    "    axs[0].plot(history.history['accuracy'], label='Train Accuracy', color='blue')\n",
    "    axs[0].plot(history.history['val_accuracy'], label='Validation Accuracy', color='orange')\n",
    "    axs[0].set_title('Accuracy over Epochs')\n",
    "    axs[0].set_xlabel('Epochs')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Loss plot\n",
    "    axs[1].plot(history.history['loss'], label='Train Loss', color='blue')\n",
    "    axs[1].plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "    axs[1].set_title('Loss over Epochs')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRWD0_I5to7_"
   },
   "outputs": [],
   "source": [
    "# Evaluate on test dataset\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PeX2mk7njSO"
   },
   "source": [
    "*For the code containing the implementation with the 50-50 dataset split, please see the other attatched notebook*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
